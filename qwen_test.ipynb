{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER_ELISEY\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "\n",
    "from trl import setup_chat_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_source_model = \"C:\\\\Users\\\\USER_ELISEY\\\\qwen\"\n",
    "path_to_finetuned_model = \"C:\\\\Users\\\\USER_ELISEY\\\\hakaton\\\\russia_mini_chad\\\\checkpoint-100\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    }
   ],
   "source": [
    "# QLoRA config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# Load model\n",
    "casual_model = AutoModelForCausalLM.from_pretrained(\n",
    "    path_to_source_model,\n",
    "    quantization_config=bnb_config,\n",
    "#     device_map=\"auto\",\n",
    "    attn_implementation=\"eager\"\n",
    ")\n",
    "\n",
    "tokenizer = tokenizer = AutoTokenizer.from_pretrained(path_to_source_model)\n",
    "tokenizer.padding_side = 'right'\n",
    "tokenizer.padding_token = '<|pad_token|>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "casual_model, tokenizer = setup_chat_format(casual_model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    path_to_finetuned_model,\n",
    "    quantization_config=bnb_config,\n",
    "#     device_map=\"auto\",\n",
    "    attn_implementation=\"eager\"\n",
    ")\n",
    "\n",
    "tokenizer = tokenizer = AutoTokenizer.from_pretrained(path_to_finetuned_model)\n",
    "tokenizer.padding_side = 'right'\n",
    "tokenizer.padding_token = '<|pad_token|>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = setup_chat_format(model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(model, prompt):\n",
    "    chat = [\n",
    "        { \"role\": \"user\", \"content\": prompt },\n",
    "    ]\n",
    "    prompt = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n",
    "    outputs = model.generate(input_ids=inputs.to(model.device), max_new_tokens=150)\n",
    "\n",
    "    return(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprasion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = \"В каком году Александр Невский поехал в орду?\"\n",
    "q2 = \"Как звали сына Сталина?\"\n",
    "q3 = \"Кто такой Брежнев?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "В каком году Александр Невский поехал в орду?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Александр Невский поехал в орду в 1887 году.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "print(generate_answer(model, q1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "Как звали сына Сталина?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Сын Сталина — это имя, которое было названо в 1930 году, когда впервые в истории СССР было официально названо имя Сталина. В 1930 году в СССР было официально названо имя Сталина, но в 1931 году было официально названо имя Сталина.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "print(generate_answer(model, q2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "Кто такой Брежнев?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Брежнев — советский и российский политический деятель, член ЦК КПСС, председатель ЦК КПСС СССР, председатель ЦК КПСС СССР, председатель ЦК КПСС СССР, председатель ЦК КПСС СССР, председатель ЦК КПСС СССР, председатель ЦК КПСС СССР, председатель ЦК КПСС СССР, председатель ЦК КПСС СССР, председ\n"
     ]
    }
   ],
   "source": [
    "print(generate_answer(model, q3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Free gpu memory\n",
    "# import numba\n",
    "# numba.cuda.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "В каком году Александр Невский поехал в орду?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "根据文本内容，以下为文本中关于“ Александр Невский поехал в орду”的部分：\n",
      "\n",
      "1. Александр Невский поехал в орду в 1918 году.\n",
      "2. Александр Невский был в орде с 1918 года по 1920 году.\n",
      "3. Александр Невский был в орде с 1918 года по 1920 году.\n",
      "4. Александр Невский был в орде с 1918 года по 1920 году.\n",
      "5. Александр Невский был в орде с 1918 года по 1920 году.\n",
      "6. Александр\n"
     ]
    }
   ],
   "source": [
    "print(generate_answer(casual_model, q1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "Как звали сына Сталина?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Based on the information provided in the text, the name of the son of Stalin is not mentioned. The text only mentions that Stalin was the leader of the Soviet Union and that he was born in 1903. There is no mention of his name or any other information about his son.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "print(generate_answer(casual_model, q2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "Кто такой Брежнев?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "The person who is the subject of the question is the former Soviet leader and Prime Minister of the Russian Federation, Boris Yeltsin.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "print(generate_answer(casual_model, q3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
